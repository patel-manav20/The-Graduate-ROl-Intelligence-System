[2025-12-07T19:25:22.078+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-12-07T19:25:22.168+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: bls_employment_projections_etl.create_table manual__2025-12-07T19:25:07.979985+00:00 [queued]>
[2025-12-07T19:25:22.212+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: bls_employment_projections_etl.create_table manual__2025-12-07T19:25:07.979985+00:00 [queued]>
[2025-12-07T19:25:22.213+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 2
[2025-12-07T19:25:22.260+0000] {taskinstance.py:2888} INFO - Executing <Task(SnowflakeOperator): create_table> on 2025-12-07 19:25:07.979985+00:00
[2025-12-07T19:25:22.344+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=355) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-07T19:25:22.369+0000] {standard_task_runner.py:72} INFO - Started process 358 to run task
[2025-12-07T19:25:22.345+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'bls_employment_projections_etl', 'create_table', 'manual__2025-12-07T19:25:07.979985+00:00', '--job-id', '80', '--raw', '--subdir', 'DAGS_FOLDER/bls_etl_dag.py', '--cfg-path', '/tmp/tmpxzvm75fy']
[2025-12-07T19:25:22.386+0000] {standard_task_runner.py:105} INFO - Job 80: Subtask create_table
[2025-12-07T19:25:22.619+0000] {task_command.py:467} INFO - Running <TaskInstance: bls_employment_projections_etl.create_table manual__2025-12-07T19:25:07.979985+00:00 [running]> on host 8f0f084825b6
[2025-12-07T19:25:22.839+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Manav Patel' AIRFLOW_CTX_DAG_ID='bls_employment_projections_etl' AIRFLOW_CTX_TASK_ID='create_table' AIRFLOW_CTX_EXECUTION_DATE='2025-12-07T19:25:07.979985+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-12-07T19:25:07.979985+00:00'
[2025-12-07T19:25:22.844+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-12-07T19:25:22.887+0000] {sql.py:266} INFO - Executing: 
    CREATE TABLE IF NOT EXISTS USER_DB_HYENA.ANALYTICS.bls_employment_projections (
        OCCUPATION_TITLE VARCHAR(500),
        JOB_TITLE VARCHAR(500),
        OCCUPATION_CODE VARCHAR(20),
        EMPLOYMENT_2024 VARCHAR(50),
        EMPLOYMENT_2034 VARCHAR(50),
        EMPLOYMENT_CHANGE_2024_2034 VARCHAR(50),
        EMPLOYMENT_PERCENT_CHANGE_2024_2034 VARCHAR(50),
        OCCUPATIONAL_OPENINGS_2024_2034_ANNUAL_AVG VARCHAR(50),
        MEDIAN_ANNUAL_WAGE_2024 VARCHAR(50),
        TYPICAL_ENTRY_LEVEL_EDUCATION VARCHAR(200),
        EDUCATION_CODE VARCHAR(10),
        WORK_EXPERIENCE_IN_RELATED_OCCUPATION VARCHAR(100),
        WORKEX_CODE VARCHAR(10),
        TYPICAL_ON_THE_JOB_TRAINING VARCHAR(100),
        TR_CODE VARCHAR(10),
        LOAD_TIMESTAMP TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()
    )
    
[2025-12-07T19:25:22.910+0000] {base.py:84} INFO - Retrieving connection 'snowflake_conn'
[2025-12-07T19:25:22.929+0000] {base.py:84} INFO - Retrieving connection 'snowflake_conn'
[2025-12-07T19:25:22.933+0000] {connection.py:413} INFO - Snowflake Connector for Python Version: 3.12.1, Python Version: 3.12.5, Platform: Linux-6.12.54-linuxkit-aarch64-with-glibc2.36
[2025-12-07T19:25:22.936+0000] {connection.py:1196} INFO - Connecting to GLOBAL Snowflake domain
[2025-12-07T19:25:22.937+0000] {connection.py:1277} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-12-07T19:25:24.243+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-12-07T19:25:24.246+0000] {sql.py:509} INFO - Running statement: CREATE TABLE IF NOT EXISTS USER_DB_HYENA.ANALYTICS.bls_employment_projections (
        OCCUPATION_TITLE VARCHAR(500),
        JOB_TITLE VARCHAR(500),
        OCCUPATION_CODE VARCHAR(20),
        EMPLOYMENT_2024 VARCHAR(50),
        EMPLOYMENT_2034 VARCHAR(50),
        EMPLOYMENT_CHANGE_2024_2034 VARCHAR(50),
        EMPLOYMENT_PERCENT_CHANGE_2024_2034 VARCHAR(50),
        OCCUPATIONAL_OPENINGS_2024_2034_ANNUAL_AVG VARCHAR(50),
        MEDIAN_ANNUAL_WAGE_2024 VARCHAR(50),
        TYPICAL_ENTRY_LEVEL_EDUCATION VARCHAR(200),
        EDUCATION_CODE VARCHAR(10),
        WORK_EXPERIENCE_IN_RELATED_OCCUPATION VARCHAR(100),
        WORKEX_CODE VARCHAR(10),
        TYPICAL_ON_THE_JOB_TRAINING VARCHAR(100),
        TR_CODE VARCHAR(10),
        LOAD_TIMESTAMP TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()
    ), parameters: None
[2025-12-07T19:25:24.736+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-12-07T19:25:24.737+0000] {sql.py:518} INFO - Rows affected: 1
[2025-12-07T19:25:24.740+0000] {snowflake.py:422} INFO - Rows affected: 1
[2025-12-07T19:25:24.740+0000] {snowflake.py:423} INFO - Snowflake query id: 01c0e5ad-0107-3356-000f-c0df00bbb99e
[2025-12-07T19:25:25.138+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-12-07T19:25:25.139+0000] {connection.py:788} INFO - closed
[2025-12-07T19:25:25.184+0000] {connection.py:794} INFO - No async queries seem to be running, deleting session
[2025-12-07T19:25:25.335+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-12-07T19:25:25.336+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=bls_employment_projections_etl, task_id=create_table, run_id=manual__2025-12-07T19:25:07.979985+00:00, execution_date=20251207T192507, start_date=20251207T192522, end_date=20251207T192525
[2025-12-07T19:25:25.376+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-12-07T19:25:25.410+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/models/baseoperator.py:1378 AirflowProviderDeprecationWarning: Call to deprecated class SnowflakeOperator. (This class is deprecated. Please use `***.providers.common.sql.operators.sql.SQLExecuteQueryOperator`. Also, you can provide `hook_params={'warehouse': <warehouse>, 'database': <database>, 'role': <role>, 'schema': <schema>, 'authenticator': <authenticator>,'session_parameters': <session_parameters>}`.)
[2025-12-07T19:25:25.430+0000] {taskinstance.py:3900} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-12-07T19:25:25.432+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
